---
title: NPFL114
layout: page
---


<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

# Týden 1


|Otázka|Odpověd|Poznámky|
|--------|---------|----------|
|Define a probability distribution|A probability distribution describes how likely are individual values a random variable can take.||
|What is the sum of all probabilities?|1||
|How do you calculate the probability of value x lies in the interval [a, b]?|<img src="media/paste-0659ac3b06d1cfd7184e5df773b3e47debd3b8f0.jpg">||
|Define probabilitistic expectation for discrete space|<img src="media/paste-d1cd90d66ba71f4fd8e6bb8065600e7589a5a6b7.jpg">||
|Define probabilitistic expectation for continous space|<img src="media/paste-61763586665f0c0567900ebd542dcd000ecf5473.jpg">||
|Is probabilistic expectation linear? And what does it mean?|Yes.&nbsp;<img src="media/paste-4a79a6d45c820547a502f158ea8546e499611ccb.jpg">||
|Define probabilistic variance|<img src="media/paste-95b2601a6981ba4ee6f940aa7c15aba27898d58d.jpg">||
|What does Bernoulli distribution look like?|<img src="media/paste-0801e7d6a68c761b351444d49d82a9fd711bb2ab.jpg">||
|Define Bernoulli's distribution properties|<img src="media/paste-e1355861c5d23b52e2a8f523a09fa9da927b14bc.jpg">||
|Define probabilistic self-information|<img src="media/paste-d8fffaeaa34a4addf9d506eb3f36a5a6baf70626.jpg"><img src="media/paste-d9151904298099e89d1c9d0f48fa8c2a0a5f7ccd.jpg"><br>||
|Define entropy|<img src="media/paste-be51f30cb631c550c04b4a379724f44581cb55ef.jpg">||
|How do you calculate entropy in discrete space?|<img src="media/paste-e7748b341b8747482d48310069eff65d0b4e1538.jpg">||
|How do you calculate entropy in continuous space?|<img src="media/paste-b400c4807fa4b556023a621a1a1a49dde109dace.jpg">||
|<img src="media/paste-5760975384e2a6c713bc1b04f76ccf1ab15f92b5.jpg"><br>Which one of those distributions is high entropy and which is low entropy?|The blue one is low entropyThe orange one is high entropy||
|How do you calculate cross entropy?|<img src="media/paste-56e89f305ff527c92cc81bd2c8c21f3ab2912f17.jpg">||
|How do you calculate KL Divergence?|<img src="media/paste-882981d0a7d224d53b087132a7af317a5d8bbfe8.jpg">||
|State the central limit theorem|<img src="media/paste-a273229976215e8aa64d80de755162a3e907c94e.jpg">||
|State the principle of maximum entropy|<img src="media/paste-2a9e9a6b36ad3d9e45603cd1222e1990823dab60.jpg">||
